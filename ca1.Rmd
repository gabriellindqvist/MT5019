---
title: "Computer Assignment 1"
author: "Gabriel Lindqvist, Jiahui Li"
date: "`r Sys.Date()`"
output: pdf_document
---

# Exercise1:1

## Task 1
Calculate the percentage in favor and against legal abortion for men and women separately.
```{r}
survey_data<- as.table(rbind(c(309, 191), c(319, 281)))
dimnames(survey_data) <- list(gender = c("women", "men"),opinion = c("favor","against"))

women_in_favor <- survey_data[1,1]
men_in_favor <- survey_data[1,2]
women_total <- sum(survey_data[1, ])
men_total <- sum(survey_data[2, ])

# Calculate percentages for women
women_percent_in_favor <- (women_in_favor / women_total) * 100
women_percent_against <- 100 - women_percent_in_favor

# Calculate percentages for men
men_percent_in_favor <- (men_in_favor / men_total) * 100
men_percent_against <- 100 - men_percent_in_favor

# Print results
cat("Women: In favor =", women_percent_in_favor, "%, Against =", women_percent_against, "%\n")
cat("Men: In favor =", men_percent_in_favor, "%, Against =", men_percent_against, "%\n")

```
The proportion of women who are in favor of legal abortion is evidently larger than men's.
## Task 2
```{r}
# Calculate Pearson's Chi-squared test
chi_squared_result <- chisq.test(survey_data, correct = FALSE)
chi_squared_result
# Calculate expected counts
expected_counts <- chi_squared_result$expected
expected_counts

# Calculate likelihood ratio statistic G^2
observed <- as.vector(survey_data)
expected <- as.vector(expected_counts)
G2 <- 2 * sum(observed * log(observed / expected))

# Print results
cat("Pearson's Chi-squared statistic (X^2):", chi_squared_result$statistic, "\n")
cat("Likelihood ratio statistic (G^2):", G2, "\n")
cat("P-value (from Chi-squared test):", chi_squared_result$p.value, "\n")

# Conclusion
if (chi_squared_result$p.value < 0.05) {
  cat("Conclusion: Reject the null hypothesis. There is a significant association between gender and opinion on legal abortion.\n")
} else {
  cat("Conclusion: Fail to reject the null hypothesis. There is no significant association between gender and opinion on legal abortion.\n")
}

```
From the output above we can see that the test statistics are large with small p-values (less than 0.01). This provides strong evidence against the null hypothesis of independence, indicating a significant association between gender and their opinions toward legal abortion.

## Task3
Next we calculate the odds ratio for women and men.
```{r}
# Calculate odds for women and men
odds_women <- survey_data[1, 1] / survey_data[1, 2]
odds_men <- survey_data[2, 1] / survey_data[2, 2]

# Odds ratio
odds_ratio <- odds_women / odds_men

# Log odds ratio and its standard error
log_odds_ratio <- log(odds_ratio)
se_log_odds_ratio <- sqrt(1 / survey_data[1, 1] + 1 / survey_data[1, 2] +
                          1 / survey_data[2, 1] + 1 / survey_data[2, 2])

# 95% confidence interval for the log odds ratio
ci_log_lower <- log_odds_ratio - 1.96 * se_log_odds_ratio
ci_log_upper <- log_odds_ratio + 1.96 * se_log_odds_ratio

# Transform back to get the confidence interval for the odds ratio
ci_lower <- exp(ci_log_lower)
ci_upper <- exp(ci_log_upper)

# Print results
cat("Odds for women (In favor / Against):", odds_women, "\n")
cat("Odds for men (In favor / Against):", odds_men, "\n")
cat("Odds Ratio (Women vs Men):", odds_ratio, "\n")
cat("95% Confidence Interval for Odds Ratio: [", ci_lower, ",", ci_upper, "]\n")

# Interpretation
if (1 < ci_lower || 1 > ci_upper) {
  cat("Interpretation: The odds of being in favor of legal abortion significantly differ between women and men.\n")
} else {
  cat("Interpretation: The odds of being in favor of legal abortion do not significantly differ between women and men.\n")
}
```
- The calculation uses **manual formulas** for:
  - OR: \( \frac{(a \cdot d)}{(b \cdot c)} \)
  - Standard Error (SE): \( \sqrt{\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d}} \)
  - CI: Based on the standard normal approximation (\(1.96 \times SE\)).

From the output above we can see that the estimated odds ratio is OR = 1.425085 with a 95% C.I as (1.119477, 1.814121). This suggests that women are more likely than men to support legal abortion. Furthermore, the C.I does not include 1, which supports that the difference is statistically significant.

# Task4
Next we calculate the risk ratio for women and men.
```{r}
# Calculate risks (probabilities of being in favor)
risk_women <- survey_data[1, 1] / women_total
risk_men <- survey_data[2, 1] / men_total

# Risk ratio
risk_ratio <- risk_women / risk_men

# Log risk ratio and its standard error
log_risk_ratio <- log(risk_ratio)
se_log_risk_ratio <- sqrt((1 / survey_data[1, 1]) - (1 / women_total) +
                          (1 / survey_data[2, 1]) - (1 / men_total))

# 95% confidence interval for the log risk ratio
ci_log_lower <- log_risk_ratio - 1.96 * se_log_risk_ratio
ci_log_upper <- log_risk_ratio + 1.96 * se_log_risk_ratio

# Transform back to get the confidence interval for the risk ratio
ci_lower <- exp(ci_log_lower)
ci_upper <- exp(ci_log_upper)

# Print results
cat("Risk for women (In favor / Total):", risk_women, "\n")
cat("Risk for men (In favor / Total):", risk_men, "\n")
cat("Risk Ratio (Women vs Men):", risk_ratio, "\n")
cat("95% Confidence Interval for Risk Ratio: [", ci_lower, ",", ci_upper, "]\n")

# Interpretation
if (1 < ci_lower || 1 > ci_upper) {
  cat("Interpretation: The relative risk of being in favor of legal abortion significantly differs between women and men.\n")
} else {
  cat("Interpretation: The relative risk of being in favor of legal abortion does not significantly differ between women and men.\n")
}
```
  - Risk Ratio:
    \[
    RR = \frac{\text{Risk for Women}}{\text{Risk for Men}}
    \]
  - Confidence Interval:
    \[
    CI = \text{exp}\left[\log(RR) \pm 1.96 \cdot SE\right]
    \]
    where:
    \[
    SE = \sqrt{\frac{1}{a} - \frac{1}{a+b} + \frac{1}{c} - \frac{1}{c+d}}
    \]
    
From the output above we can see that the estimated risk ratio RR = 1.162382 with a 95% C.I as (1.049742, 1.287109). This suggests that womenâ€™s relative risk of being in favor of legal abortion is 1.162 times that of men. Furthermore, the C.I does not include 1, which supports that the difference is statistically significant relative to gender.
## Task5
### Run the code given by the file to address Q1-4
```{r}
#Generate a frequency table and calculate row percentage
tab1<- as.table(rbind(c(309, 191), c(319, 281)))
dimnames(tab1) <- list(gender = c("women", "men"),opinion = c("favor","against"))
addmargins(tab1)
addmargins(prop.table(tab1,1),2)

#Calculate X2, G2 and p-values
chisq.test(tab1,correct=FALSE)
library(MASS) 
loglm(~gender+opinion,tab1)
```
The test statistics are equal to the results generated form the basic R code, which also indicates a significant association between gender and the opinions toward legal abortion.
```{r}
#Calculate odds ratio and confidence interval
library(epitools) 
oddsratio(tab1, method = "wald", rev="neither")$measure
```
Both the basic R calculation and the `oddsratio()` function provide similar results for the **Odds Ratio (OR)**, but there are small differences in the confidence interval (CI) and methodological details. Differences are due to implementation precision, but they are negligible and do not impact the interpretation.
```{r}
#Calculate risk ratio and confidence interval
riskratio(tab1,rev="both")$measure
```
Both the basic R calculation and the `riskratio()` function provide similar results for the **Risk Ratio (RR)**, but there are small differences in the confidence interval (CI) and methodological details. Differences are due to implementation precision, but they are negligible and do not impact the interpretation.

# Exercise 1:2

## Task 1

First we enter the given data in R and generate a contingency table.

```{r}
tab2 <- as.table(rbind(c(557, 1835 - 557), c(1198, 2691 - 1198)))
dimnames(tab2) <- list(gender = c("women", "men"), admission = c("admitted", "not admitted"))
addmargins(tab2)
addmargins(prop.table(tab2, 1), 2)
```

Next, we want to do make the same analysis as in Exercise 1:1. Firstly we can test whether there is an association between gender and admission using $\chi^2$ and $G^2$ statistics.

```{r}
library(MASS)

# Calculate chi-sq statistic, LR statistic and p-values
loglm(~gender + admission, tab2)
```

From the output above we can see that the test statistics are large with small p-values (less than 0.01). This provides strong evidence against the null hypothesis of independence, indicating a significant association between gender and admission.

Next, we calculate the odds ratio of admission for men relative relative to women.

```{r}
library(epitools)

# Calculate the odds ratio
oddsratio(tab2, method = "wald", rev = "col")$measure
```

From the output above we can see that the estimated odds ratio is $\text{OR} = 1.841$ with a $95\%$ C.I as $(1.624, 2.087)$. This suggests that that men have higher odds of being admitted compared to women. Furthermore, the CI does not include 1, which supports that the difference is statistically significant.

Lastly, we compute the risk ratio for men relative to women.

```{r}
# Calculate the risk ratio
riskratio(tab2, rev = "col")$measure
```

From the output above we can see that the estimate risk ratio $\text{RR} = 1.467$ with a $95\%$ C.I as $(1.352, 1.591)$. This indicates that men are $46.7\%$ more likely of being admitted compared to women. The C.I does not include 1 here, which further supports that there is a distinct difference in admission relative to gender.

## Task 2
The next task is to investigate the effect of replacing all values in the contingency table with one-tenth of the original values, and then comment on what we observe.

```{r}
tab2_2 <- round(tab2 / 10)
addmargins(tab2_2)
addmargins(prop.table(tab2_2, 1), 2)

loglm(~gender + admission, tab2_2)

oddsratio(tab2_2, method = "wald", rev = "col")$measure

riskratio(tab2_2, method = "wald", rev = "col")$measure
```

First we observe that the Pearson's and LR statistics values change by $1/10$, which yields higher p-values. Secondly we observe that the estimates for the odds and risk ratios are still the same. However, the $95\%$ C.I are much wider compared to using the original data. This is expected, because smaller sample sizes introduces greater uncertainty, ultimately reducing the precision of the estimates.

Next, we repeat by replacing the numbers with one hundredth of the original values.

```{r}
tab2_2 <- round(tab2_2 / 10)
addmargins(tab2_2)
addmargins(prop.table(tab2_2, 1), 2)

loglm(~gender + admission, tab2_2)

oddsratio(tab2_2, method = "wald", rev = "col")$measure

riskratio(tab2_2, method = "wald", rev = "col")$measure
```

The estimated odds and risk ratios are roughly the same as the original ones, which is expected since we just scale the data entries with $1/100$ and then round the values. Further, the statistics have also been scaled with approximately $1/100$ compared to the statistics in Task 1, which is why the p-values are now larger. Lastly the $95\%$ C.I are much wider now and does also include 1 in them (which is expected with smaller sample sizes).

## Task 3
In this task we want to create a new two-way contingency table that satisfy the following conditions:

- The sample odds ratio $\hat{\theta}$ is within the interval $(0.99, 1.01)$.

- The population odds ratio $\theta$ is significantly different from 1.

Finally, we will comment on the relevance of declaring 'statistical significance' in a situation the one like above.

### Creating the Contingency Table

In order for $\hat{\theta}$ to satisfy the first condition, we know that each cell count $n_{ij}, \ i,j = 1, 2$ needs to be approximately the same such that

$$
\hat{\theta} = \frac{n_{11} \cdot n_{22}}{n_{12} \cdot n_{21}} \approx 1.
$$

To satisfy the second condition, we need larger $n_{ij}$, as larger sample sizes increase statistical power, making small imbalances more likely to yield significant results. With the reasoning above, we construct the following contingency table

```{r}
tab3 <- as.table(rbind(c(200000, 199000), c(199000, 200000)))
dimnames(tab3) <- list(group = c("Group 1", "Group 2"), outcome = c("Outcome 1", "Outcome 2"))

oddsratio(tab3, method = "wald")$data
oddsratio(tab3, method = "wald")$measure
```

From above, we observe that the sample odds ratio satisfies the first condition, with $\hat{\theta} \approx 1.01$. Next, we test whether the second condition holds.

```{r}
loglm(~group + outcome, tab3)
```

The test output shows that the null hypothesis of independence is rejected at the $5\%$ significance level. Thus satisfying the second condition.

### Comments on Above Results
The results above highlights the fact that statistical tests are sensitive to small imbalances when sample sizes are large, even if the sample odds ratio is weak. In the case above, the sample odds ratio indicates that there is no association, yet the large sample size leads to a significant test. This demonstrates that statistical significance does not always equate to practical relevance, which is why relying solely on statistical significance can be misleading in cases like the one above. Instead, both the sample odds ratio and the tests should be included when reporting the results, whilst weighing the relevance of the test.


